{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import sys  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyung/Research23_Network_Analysis/mBIN/FTD_JupyterNotebook/Load_Dataset\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r loadData_hf\n",
    "sys.path.insert(0, loadData_hf)\n",
    "import findPathCoM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Directory Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the data folder\n",
    "%store -r dataDir\n",
    "\n",
    "# Directory path where Data will be saved to\n",
    "%store -r path_dataDir\n",
    "\n",
    "# Only used to load the FTDGeneralData_20221114.mat file --> Saved as NetworkDataGeneral\n",
    "%store -r baseDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the preconstructed atlas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the preconstructed Atlas data\n",
    "NetworkDataGeneral = scipy.io.loadmat(os.path.join(baseDir, 'NetworkAnalysisGeneral', 'FTDGeneralData_20221114.mat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] Loading Pathology Dataset - %AO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new_pathT: ex-vivo histopathology Data (Quantification) / %AO for pathology regions\n",
    "new_pathT = pd.read_excel(os.path.join(dataDir, 'NewFTDData', 'FTLD Library 4-25-23 update.xlsx'), \n",
    "                          dtype={'INDDID': str, 'Tau1_TDP2': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the Pathology Data - %AO to desired format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide each INDDID into {GM, WM} and {L, R} - 22 Regions (They are alphabetically Ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each INDDID divided into {GM, WM} and {L, R} (maximum 4 rows per INDDID)\n",
    "pathT_WMGM = pd.pivot_table(new_pathT, values='AvgPercentAO', \n",
    "                            index=['INDDID', 'FullAutopsyID', 'AutopsyIDNumOnly', \n",
    "                                   'Tau1_TDP2', 'Hemisphere_by_slide', 'AnalysisRegion'], \n",
    "                            columns=['Region'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstacking the Index --> Need a way to solve this without saving to csv format\n",
    "pathT_WMGM.to_csv(os.path.join(dataDir, 'NewFTDData', 'new_pathT(GMWM).csv'))\n",
    "pathT_WMGM = pd.read_csv(os.path.join(dataDir, 'NewFTDData', 'new_pathT(GMWM).csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide the pathT into GM and WM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathT_WMGM_type = pathT_WMGM.groupby('AnalysisRegion')\n",
    "\n",
    "# This contains 2 seperate rows for {L, R}\n",
    "pathT_GM_LR = pathT_WMGM_type.get_group('GM')\n",
    "pathT_WM_LR = pathT_WMGM_type.get_group('WM')\n",
    "\n",
    "# Combine 2 Rows for {L, R} into a single row\n",
    "pathT_GM_LR_type = pathT_GM_LR.groupby('Hemisphere_by_slide')\n",
    "pathT_GM_L = pathT_GM_LR_type.get_group('L')\n",
    "pathT_GM_R = pathT_GM_LR_type.get_group('R')\n",
    "pathT_GM = pd.merge(pathT_GM_L, pathT_GM_R, left_on=['INDDID', 'FullAutopsyID', 'AutopsyIDNumOnly', 'Tau1_TDP2', 'AnalysisRegion'], right_on=['INDDID', 'FullAutopsyID', 'AutopsyIDNumOnly', 'Tau1_TDP2', 'AnalysisRegion'], how='outer', suffixes=('_L', '_R')) \n",
    "\n",
    "pathT_WM_LR_type = pathT_WM_LR.groupby('Hemisphere_by_slide')\n",
    "pathT_WM_L = pathT_WM_LR_type.get_group('L')\n",
    "pathT_WM_R = pathT_WM_LR_type.get_group('R')\n",
    "pathT_WM = pd.merge(pathT_WM_L, pathT_WM_R, left_on=['INDDID', 'FullAutopsyID', 'AutopsyIDNumOnly', 'Tau1_TDP2', 'AnalysisRegion'], right_on=['INDDID', 'FullAutopsyID', 'AutopsyIDNumOnly', 'Tau1_TDP2', 'AnalysisRegion'], how='outer', suffixes=('_L', '_R'))\n",
    "\n",
    "# Drop Hemisphere_by_slide {L, R} Columns\n",
    "pathT_GM = pathT_GM.drop(columns=['Hemisphere_by_slide_L', 'Hemisphere_by_slide_R'])\n",
    "pathT_WM = pathT_WM.drop(columns=['Hemisphere_by_slide_L', 'Hemisphere_by_slide_R']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Mapping Pathology Regions to Atlas regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Look up table matching Atlas Region names to Atlas Labels(Index)\n",
    "pathLUT = pd.read_csv(os.path.join(dataDir,'schaefer_path_20210719_20220328.csv'))\n",
    "\n",
    "# Load the Look up table matching Pathology Region names to Atlas Region names\n",
    "AtlasToPathLUT = pd.read_excel(os.path.join(dataDir,'NewFTDData','PathToAtlasLUT_5_10_2023(mePFC_PFC_Ignored).xlsx'))\n",
    "\n",
    "# Using AtlasToPathLUT get the Pathology Regions and match them to Atlas Regions (Index 1~400 regions)\n",
    "# Return CoM for each Pathology Regions (Single Pahtology Regions match to multiple Atlas Regions, \n",
    "# therefore get Mean Value). Theses are unordered.\n",
    "# Also return list of Atlas regions index corrresponding to Pathology regions. Theses are unordered.\n",
    "pathCoMunordered, pathToAtlasIndexunordered = findPathCoM.findPathCoM(pathLUT, AtlasToPathLUT, \n",
    "                                                                      NetworkDataGeneral['NetworkDataGeneral'][0,0]['Schaefer400x7']['CoM'][0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get List of all regions of pathology we can map to 3D Atlas (out of 22) in Alphabetical Order\n",
    "# ['ANG', 'ATC', 'HIP', 'IFC', 'M1', 'MFC', 'OFC', 'PC', 'S1', 'SMTC', 'SPC', 'V1', 'aCING', 'aINS', 'aITC', 'dlPFC', 'iPFC', 'mPFC', 'pCING', 'pSTC']\n",
    "pathNames_3D_Map = np.sort(AtlasToPathLUT[\"PathSpreadSheetNames\"].values)\n",
    "\n",
    "# sn - denote the number of areas we are able to map to 3D Atlas\n",
    "sn = len(pathNames_3D_Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering the CoM so that it matches the order of Regions in the Pathology Dataset - %AO (Columns)\n",
    "pathCoM = np.empty((sn,3,2)) # One path regions corresponds to multiple atlas region\n",
    "pathToAtlasIndex = [[None, None] for _ in range(sn)]\n",
    "\n",
    "for s in range(sn):\n",
    "    idx = AtlasToPathLUT[AtlasToPathLUT.PathSpreadSheetNames == pathNames_3D_Map[s]].index[0] \n",
    "    pathCoM[s,:,:] = pathCoMunordered[idx, :, :]\n",
    "    pathToAtlasIndex[s] = pathToAtlasIndexunordered[idx]\n",
    "\n",
    "# pathCoM and pathToAtlasIndex are ordered by the order of pathNames_3D_Map (= Ordering of regions same as in PathT Dataset Columns Left to Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns in pathT_GM / pathT_GM Where we cannot map to 3D Atlas, using AtlasToPathLUT (+5, for index offset)\n",
    "pathT_GM = pathT_GM.drop(pathT_GM.columns[[i + 5 for i, e in enumerate(pathT_GM.columns.values[5:]) if e.split(\"_\")[0] not in pathNames_3D_Map]], axis = 1)\n",
    "pathT_WM = pathT_WM.drop(pathT_WM.columns[[i + 5 for i, e in enumerate(pathT_WM.columns.values[5:]) if e.split(\"_\")[0] not in pathNames_3D_Map]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] TAU and TDP Divide (GM) + Log %AO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get index of rows that are TAU and TDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for the case with tau or tdp for patients\n",
    "FTD_TAUIndx = (pathT_GM.Tau1_TDP2 == 1)  # False or True\n",
    "FTD_TDPIndx = (pathT_GM.Tau1_TDP2 == 2) # False or True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100551.  , 101068.  , 101105.  , 102149.  , 103032.  , 105000.  ,\n",
       "       105223.  , 105358.  , 105492.  , 105961.  , 106297.  , 106309.  ,\n",
       "       106814.  , 106840.  , 107516.  , 107663.  , 107969.  , 108026.  ,\n",
       "       108077.  , 108196.  , 108508.  , 109115.  , 109176.  , 109299.  ,\n",
       "       109759.  , 110181.  , 110306.  , 110745.  , 110914.  , 110917.  ,\n",
       "       111231.  , 111527.  , 111530.  , 112570.  , 113113.  , 113909.  ,\n",
       "       113938.  , 115001.  , 115592.  , 116504.  , 116591.  , 116607.  ,\n",
       "       118011.  , 118410.  , 118780.  , 119113.  , 119140.  , 119359.  ,\n",
       "       119413.  , 120298.  , 122143.  , 101407.  , 101483.  , 103121.  ,\n",
       "       103782.  , 104281.  , 104937.  , 105564.  , 107187.  , 107429.  ,\n",
       "       107667.  , 107677.  , 109048.  , 111005.  , 111853.  , 112514.  ,\n",
       "       112764.  , 114348.  , 114762.  , 114762.02, 115327.  , 116275.  ,\n",
       "       116401.  , 116409.  , 117566.  , 118575.  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathT_GM[FTD_TAUIndx]['INDDID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100071.  , 100686.  , 102792.  , 103282.  , 103601.  , 103640.  ,\n",
       "       103703.  , 103714.  , 104156.  , 104613.  , 104659.  , 104862.  ,\n",
       "       105247.  , 105686.  , 105769.  , 106335.  , 106461.  , 106641.  ,\n",
       "       107031.  , 108276.  , 108344.  , 108783.  , 108783.09, 109058.  ,\n",
       "       109073.  , 109206.  , 109476.  , 110338.  , 110361.  , 110445.  ,\n",
       "       110581.  , 110658.  , 110705.  , 111077.  , 112202.  , 112273.  ,\n",
       "       112298.  , 112780.  , 112974.  , 113867.  , 114076.  , 114395.  ,\n",
       "       114753.  , 116521.  , 116569.  , 116598.  , 116748.  , 117589.  ,\n",
       "       117630.  , 117637.  , 117663.  , 117753.  , 118190.  , 118234.  ,\n",
       "       118430.  , 118694.  , 118762.  , 118914.  , 118952.  , 119454.  ,\n",
       "       119610.  , 119768.  , 120720.  , 120950.  , 121078.  , 121199.  ,\n",
       "       121261.  , 100096.  , 101045.  , 101272.  , 101525.  , 101778.  ,\n",
       "       103568.  , 104094.  , 106955.  , 107204.01, 107519.  , 107636.  ,\n",
       "       108542.  , 108790.  , 108930.  , 109050.  , 109757.  , 111092.  ,\n",
       "       111517.  , 111612.  , 111862.  , 111863.  , 113227.  , 114978.  ,\n",
       "       115017.  , 116524.  , 116561.  , 117281.  , 117468.  , 117515.  ,\n",
       "       117774.  , 118621.  , 118765.  , 118935.  , 119010.  , 119052.  ,\n",
       "       120814.  ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathT_GM[FTD_TDPIndx]['INDDID'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Log %AO of Pathology Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Log %AO of 22 anatomical regions of the brain\n",
    "#pathData = np.ma.log(0.01 * pathT.iloc[:, 5:].values + 0.00015).filled(np.nan) # Masked log for handling the case where the value is NaN\n",
    "pathData = np.ma.log(pathT_GM.iloc[:, 5:].values + 0.00015).filled(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NO LOG!!\n",
    "# pathData = pathT_GM.iloc[:, 5:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Pathology Data into TAU and TDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log %AO of FTD TAU vs TDP --> Type: ndarray\n",
    "path_TAU = pathData[FTD_TAUIndx,:]\n",
    "path_TDP = pathData[FTD_TDPIndx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Unique INNDID in whole dataset\")\n",
    "print(len(pd.unique(pathT_WMGM['INDDID'])))\n",
    "print(\"Unique INDDID in GM\")\n",
    "print(len(pd.unique(pathT_GM_LR['INDDID'])))\n",
    "print(\"Unique INDDID in WM\")\n",
    "print(len(pd.unique(pathT_WM_LR['INDDID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(pathT_GM_LR['INDDID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Dataset and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save pathT GM/WM to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pathT GM/WM to csv\n",
    "pathT_GM.to_csv(os.path.join(path_dataDir, 'new_pathT(GM).csv'), index=False)\n",
    "pathT_WM.to_csv(os.path.join(path_dataDir, 'new_pathT(WM).csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_dataDir, 'sn.pkl'), 'wb') as f:\n",
    "    pickle.dump(sn, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save pathCoM, pathToAtlasIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_dataDir, 'pathCoM.pkl'), 'wb') as f:\n",
    "    pickle.dump(pathCoM, f)\n",
    "f.close()\n",
    "\n",
    "with open(os.path.join(path_dataDir, 'pathToAtlasIndex.pkl'), 'wb') as f:\n",
    "    pickle.dump(pathToAtlasIndex, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save TAU and TDP Pathology Data (Log %AO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_TAU\n",
    "with open(os.path.join(path_dataDir, 'path_TAU.pkl'), 'wb') as f:\n",
    "    pickle.dump(path_TAU, f)\n",
    "f.close()\n",
    "\n",
    "# path_TDP\n",
    "with open(os.path.join(path_dataDir, 'path_TDP.pkl'), 'wb') as f:\n",
    "    pickle.dump(path_TDP, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Network_Analysis",
   "language": "python",
   "name": "network_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
